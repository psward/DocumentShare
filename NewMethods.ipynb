{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gerrychain import Graph, Election, updaters, Partition, MarkovChain, constraints\n",
    "from gerrychain.proposals import recom\n",
    "from gerrychain.accept import always_accept\n",
    "from gerrychain.tree import random_spanning_tree, PopulatedGraph, predecessors\n",
    "from collections import deque, namedtuple\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "Cut = namedtuple(\"Cut\", \"edge subset\")\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "#     THIS IS NO LONGER NEEDED, BUT IS HANDY FOR CHECKING THE SIZE OF THE PARTITIONS     #\n",
    "#                 TURN IT OFF AND REMOVE CONSTRAINT FOR ACTUAL RUNS                      #\n",
    "##########################################################################################\n",
    "# def stop_disappearing(partition):                                                      #\n",
    "#     if not partition.parent:                                                           #\n",
    "#         return True                                                                    #\n",
    "#     sizes_now = [len(part) for part in partition.assignment.parts.values()]            #\n",
    "#     sizes_past = [len(part) for part in partition.parent.assignment.parts.values()]    #\n",
    "#     print(sizes_now, min(sizes_past), max(sizes_past))                                 #\n",
    "#     return all(len(part) > 1 for part in partition.assignment.parts.values())          #\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "def find_balanced_edge_cuts(h, choice=random.choice):\n",
    "    root = choice([x for x in h if h.degree(x) > 2])\n",
    "    pred = predecessors(h.graph, root)\n",
    "    cuts = []\n",
    "    leaves = deque(x for x in h if h.degree(x) == 1)\n",
    "    while len(leaves) > 0:\n",
    "        leaf = leaves.popleft()\n",
    "        cuts.append(Cut(edge=(leaf, pred[leaf]), subset=h.subsets[leaf].copy()))\n",
    "        parent = pred[leaf]\n",
    "        h.contract_node(leaf, parent)\n",
    "        if h.degree(parent) == 1 and parent != root:\n",
    "            leaves.append(parent)\n",
    "            \n",
    "    even_split = int(len(h.graph.nodes)/2)\n",
    "    #cut_lengths is number of nodes in one of the districts after cut of a specific edge\n",
    "    cut_lengths = np.asarray([len(cuts[i].subset) for i in range(len(cuts))])\n",
    "    cut_distances = np.abs(cut_lengths-even_split)\n",
    "    cut_distances, cuts = zip(*sorted(zip(cut_distances, cuts)))\n",
    "    cut_distances = list(filter(lambda a: a != max(cut_distances), cut_distances))\n",
    "    \n",
    "    temp_d = {}\n",
    "    for i in range(len(cut_distances)):\n",
    "        temp_d[i] = cut_distances[i]\n",
    "    #print(temp_d)\n",
    "        # indices of cut_distances\n",
    "    population = list(range(len(cut_distances)))\n",
    "    weight_small_d = (1/(np.asarray(cut_distances)**2+1))\n",
    "    probs = weight_small_d/sum(weight_small_d)\n",
    "#     print(probs)\n",
    "    choice = random.choices(population, probs)[0]\n",
    "#     print(choice)\n",
    "############################################################################## \n",
    "#   VERIFIES THAT YOU ARE SAMPLING FROM ALL POSSIBLE EDGE CHOICES CORRECTLY  #\n",
    "##############################################################################\n",
    "#     d = Counter(random.choices(population, probs, k=100000))               #\n",
    "#     fig = plt.figure(figsize=(12,12))                                      #\n",
    "#     ax = fig.add_subplot(2, 1, 1)                                          #\n",
    "#     plt.bar(d.keys(), d.values(), width=1.0, color='g')                    #\n",
    "#     ax.set_yscale('log')                                                   #\n",
    "#     plt.show()                                                             #\n",
    "#     print(d)                                                               #\n",
    "##############################################################################\n",
    "    return [cuts[choice]]\n",
    "\n",
    "\n",
    "def partition_tree(graph, pop_col, pop_target, epsilon, node_repeats=1, spanning_tree=None, choice=random.choice):\n",
    "    populations = {node: graph.nodes[node][pop_col] for node in graph}\n",
    "    possible_cuts = []\n",
    "    spanning_tree = random_spanning_tree(graph)\n",
    "    while len(possible_cuts) == 0:\n",
    "        spanning_tree = random_spanning_tree(graph)\n",
    "        h = PopulatedGraph(spanning_tree, populations, pop_target, epsilon)\n",
    "        possible_cuts = find_balanced_edge_cuts(h, choice=choice)\n",
    "    return choice(possible_cuts).subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#                    *HASHING AND COMPRESSING*                    #\n",
    "# THE PythonObjectEncoder CLASS SERIALIZES GENERIC PYTHON OBJECTS #\n",
    "#         THESE OBJECTS CAN THEN BE COMPRESSED AND SAVED          #\n",
    "###################################################################\n",
    "from json import JSONEncoder, dumps, loads\n",
    "from io import BytesIO\n",
    "import hashlib\n",
    "import pickle\n",
    "import gzip\n",
    "from os import path\n",
    "\n",
    "\n",
    "class PythonObjectEncoder(JSONEncoder):\n",
    "    def __init__(self, partition):\n",
    "        self.partition = partition\n",
    "        self.keys = sorted(list(initial_partition.parts.keys()))\n",
    "        self.objstrings = []\n",
    "        self.hashstrings = []\n",
    "        self.d_plan = dict.fromkeys(self.keys)\n",
    "        \n",
    "        \n",
    "    def __call__(self, obj):\n",
    "        if isinstance(obj, (list, dict, str, bytes, int, float, bool, type(None))):\n",
    "            return JSONEncoder.default(self, obj)\n",
    "        return {'_python_object': pickle.dumps(obj)}\n",
    "    \n",
    "    \n",
    "    def update(self, partition):\n",
    "        for i in range(len(self.keys)):\n",
    "            self.d_plan[self.keys[i]] = list(partition.assignment.parts[self.keys[i]])\n",
    "        encoded_plan = dumps(self.d_plan)\n",
    "        compressed_plan = PythonObjectEncoder.compressStringToBytes(encoded_plan)\n",
    "        hashstring = hashlib.md5(encoded_plan.encode('utf-8')).hexdigest()\n",
    "        self.objstrings.append(compressed_plan)\n",
    "        self.hashstrings.append(hashstring)\n",
    "        \n",
    "        \n",
    "    def commit(self, file_name):\n",
    "        final_table = dict(zip(self.hashstrings,self.objstrings))\n",
    "        self.save_obj(final_table, file_name)\n",
    "        \n",
    "        \n",
    "    def load_maps(self, file_name):\n",
    "        decode_test = self.load_obj(file_name)\n",
    "        recreated_maps = []\n",
    "        for key in decode_test:\n",
    "            recreated_maps.append(loads(PythonObjectEncoder.decompressBytesToString(decode_test[key])))\n",
    "        return recreated_maps\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def compressStringToBytes(inputString):\n",
    "        bio = BytesIO()\n",
    "        bio.write(inputString.encode(\"utf-8\"))\n",
    "        bio.seek(0)\n",
    "        stream = BytesIO()\n",
    "        compressor = gzip.GzipFile(fileobj=stream, mode='w')\n",
    "        while True:\n",
    "            chunk = bio.read(8192)\n",
    "            if not chunk:\n",
    "                compressor.close()\n",
    "                return stream.getvalue()\n",
    "            compressor.write(chunk)\n",
    "\n",
    "            \n",
    "    @staticmethod\n",
    "    def decompressBytesToString(inputBytes):\n",
    "        bio = BytesIO()\n",
    "        stream = BytesIO(inputBytes)\n",
    "        decompressor = gzip.GzipFile(fileobj=stream, mode='r')\n",
    "        while True:\n",
    "            chunk = decompressor.read(8192)\n",
    "            if not chunk:\n",
    "                decompressor.close()\n",
    "                bio.seek(0)\n",
    "                return bio.read().decode(\"utf-8\")\n",
    "            bio.write(chunk)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def save_obj(obj, name):\n",
    "        if path.exists(name + '.pkl'):\n",
    "            prev_map = PythonObjectEncoder.load_obj(name)\n",
    "            final_map = {**prev_map, **obj}\n",
    "            with open(name + '.pkl', 'rb+') as f:\n",
    "                pickle.dump(final_map, f, pickle.HIGHEST_PROTOCOL)\n",
    "        else:\n",
    "            with open(name + '.pkl', 'wb') as f:\n",
    "                pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def load_obj(name):\n",
    "        with open(name + '.pkl', 'rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"TX_vtds_fixed\"\n",
    "graph = Graph.from_json(f\"{filename}.json\")\n",
    "\n",
    "office, year = \"PRES\", \"16\"\n",
    "pop_used = \"TOTPOP\"\n",
    "area = \"area\"\n",
    "assign = \"USCD\"\n",
    "\n",
    "elect = office + year\n",
    "elect_D = elect + \"D\"\n",
    "elect_R = elect + \"R\"\n",
    "\n",
    "elections = Election(elect, {\"Dem\": elect_D, \"Rep\": elect_R})\n",
    "\n",
    "my_updaters = {\"population\": updaters.Tally(pop_used, alias=\"population\"), elect: elections}\n",
    "initial_partition = Partition(\n",
    "    graph,\n",
    "    assignment=assign,\n",
    "    updaters=my_updaters\n",
    ")\n",
    "\n",
    "ideal_population = sum(initial_partition[\"population\"].values()) / len(initial_partition)\n",
    "\n",
    "proposal = partial(\n",
    "    recom,\n",
    "    pop_col=pop_used,\n",
    "    pop_target=ideal_population,\n",
    "    epsilon=1,\n",
    "    node_repeats=2,\n",
    "    method=partition_tree\n",
    ")\n",
    "\n",
    "chain = MarkovChain(\n",
    "    proposal=proposal,\n",
    "    accept=always_accept,\n",
    "    constraints = [constraints.contiguous],\n",
    "    initial_state=initial_partition,\n",
    "    total_steps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "running\n",
      "CPU times: user 1.04 s, sys: 0 ns, total: 1.04 s\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "poe = PythonObjectEncoder(initial_partition)\n",
    "\n",
    "for partition in chain:\n",
    "    poe.update(partition)\n",
    "    print(\"running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.39 ms, sys: 0 ns, total: 2.39 ms\n",
      "Wall time: 1.18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "poe.commit('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 ms, sys: 0 ns, total: 14.2 ms\n",
      "Wall time: 11.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reloaded_maps = poe.load_maps('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master Env",
   "language": "python",
   "name": "master-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
